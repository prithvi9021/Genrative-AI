{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages\n",
    "!pip install -q langchain faiss-cpu sentence-transformers==2.2.2 InstructorEmbedding pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from pypdf import PdfReader\n",
    "from langchain import HuggingFaceHub\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA, ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pdf documents\n",
    "documents_1 = ''\n",
    "\n",
    "reader = PdfReader('wikipedia_naruto.pdf')\n",
    "for page in reader.pages:\n",
    "    documents_1 += page.extract_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_1[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document Splitting\n",
    "chunk_size = 200\n",
    "chunk_overlap = 10\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap\n",
    ")\n",
    "split_1 = splitter.split_text(documents_1)\n",
    "split_1 = splitter.create_documents(split_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load txt documents\n",
    "reader = TextLoader('wikipedia_snake.txt')\n",
    "reader = reader.load()\n",
    "print(len(reader))\n",
    "documents_2 = reader[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_2.page_content[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document Splitting\n",
    "split_2 = splitter.split_text(documents_2.page_content)\n",
    "split_2 = splitter.create_documents(split_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding and storing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load embeddings instructor\n",
    "instructor_embeddings = HuggingFaceInstructEmbeddings(\n",
    "    model_name='hkunlp/instructor-xl', model_kwargs={'device':'cuda'}\n",
    ")\n",
    "\n",
    "# Implement embeddings\n",
    "db = FAISS.from_documents(split_1, instructor_embeddings)\n",
    "\n",
    "# Save db\n",
    "db.save_local('vector store/naruto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement embeddings for the second doc\n",
    "db_2 = FAISS.from_documents(split_2, instructor_embeddings)\n",
    "\n",
    "# Save db\n",
    "db_2.save_local('vector store/snake')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge two DBs\n",
    "db.merge_from(db_2)\n",
    "db.save_local('vector store/naruto_snake')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer retrieval and generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Hugging Face token\n",
    "from google.colab import userdata\n",
    "token = userdata.get('huggingface_write')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load db\n",
    "loaded_db = FAISS.load_local(\n",
    "    'vector store/naruto_snake', instructor_embeddings, allow_dangerous_deserialization=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve answer\n",
    "question = 'what is naruto?'\n",
    "\n",
    "search = loaded_db.similarity_search(question)\n",
    "search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query more or less text chunks\n",
    "search = loaded_db.similarity_search(question, k=6)\n",
    "search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_scores = loaded_db.similarity_search_with_score(question)\n",
    "search_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_db.similarity_search_with_score(question, k=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = 1\n",
    "max_length = 300\n",
    "llm_model = 'tiiuae/falcon-7b-instruct'\n",
    "\n",
    "# Load LLM\n",
    "llm = HuggingFaceHub(\n",
    "    repo_id=llm_model,\n",
    "    model_kwargs={'temperature': temperature, 'max_length': max_length},\n",
    "    huggingfacehub_api_token=token\n",
    ")\n",
    "\n",
    "# Create the chatbot\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type='stuff',\n",
    "    retriever=loaded_db.as_retriever(),\n",
    "    return_source_documents=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask a question\n",
    "question = 'what is naruto?'\n",
    "response = qa({'query': question})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask a question\n",
    "question = 'what is naruto?'\n",
    "response = qa({'query': question})\n",
    "answer = response.get('result').split('Helpful Answer:')[1].strip()\n",
    "explanation = response.get('source_documents', [])\n",
    "print(answer)\n",
    "explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask a question\n",
    "question = 'do you know whom I am talking about?'\n",
    "response = qa({'query': question})\n",
    "answer = response.get('result').split('Helpful Answer:')[1].strip()\n",
    "explanation = response.get('source_documents', [])\n",
    "print(answer)\n",
    "explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask a question\n",
    "question = 'what happened with the seven tailed beasts?'\n",
    "response = qa({'query': question})\n",
    "answer = response.get('result').split('Helpful Answer:')[1].strip()\n",
    "explanation = response.get('source_documents', [])\n",
    "print(answer)\n",
    "explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask a question\n",
    "question = 'are there any species similar to snakes?'\n",
    "response = qa({'query': question})\n",
    "answer = response.get('result').split('Helpful Answer:')[1].strip()\n",
    "explanation = response.get('source_documents', [])\n",
    "print(answer)\n",
    "explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask a question\n",
    "question = 'summarize about venomous snakes'\n",
    "response = qa({'query': question})\n",
    "answer = response.get('result').split('Helpful Answer:')[1].strip()\n",
    "explanation = response.get('source_documents', [])\n",
    "print(answer)\n",
    "explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask a question\n",
    "question = 'how to cook rice?'\n",
    "response = qa({'query': question})\n",
    "answer = response.get('result').split('Helpful Answer:')[1].strip()\n",
    "explanation = response.get('source_documents', [])\n",
    "print(answer)\n",
    "explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask a question\n",
    "question = 'hi, how are you?'\n",
    "response = qa({'query': question})\n",
    "answer = response.get('result').split('Helpful Answer:')[1].strip()\n",
    "explanation = response.get('source_documents', [])\n",
    "print(answer)\n",
    "explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try higher temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = 3\n",
    "max_length = 600\n",
    "llm_model = 'mistralai/Mistral-7B-Instruct-v0.2'\n",
    "\n",
    "# Load LLM\n",
    "llm = HuggingFaceHub(\n",
    "    repo_id=llm_model,\n",
    "    model_kwargs={'temperature': temperature, 'max_length': max_length},\n",
    "    huggingfacehub_api_token=token\n",
    ")\n",
    "\n",
    "# Create the chatbot\n",
    "qa_high_temp = RetrievalQA.from_chain_type(\n",
    "    llm=llm, chain_type='stuff',\n",
    "    retriever=loaded_db.as_retriever(),\n",
    "    return_source_documents=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask a question\n",
    "question = 'what is naruto?'\n",
    "response = qa_high_temp({'query': question})\n",
    "answer = response.get('result').split('Helpful Answer:')[1].strip()\n",
    "explanation = response.get('source_documents', [])\n",
    "print(answer)\n",
    "explanation\n",
    "# It is hallucinating. Need to lower the temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = 1.5\n",
    "max_length = 600\n",
    "llm_model = 'mistralai/Mistral-7B-Instruct-v0.2'\n",
    "\n",
    "# Load LLM\n",
    "llm = HuggingFaceHub(\n",
    "    repo_id=llm_model,\n",
    "    model_kwargs={'temperature': temperature, 'max_length': max_length},\n",
    "    huggingfacehub_api_token=token\n",
    ")\n",
    "\n",
    "# Create the chatbot\n",
    "qa_high_temp = RetrievalQA.from_chain_type(\n",
    "    llm=llm, chain_type='stuff',\n",
    "    retriever=loaded_db.as_retriever(),\n",
    "    return_source_documents=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask a question\n",
    "question = 'what is naruto?'\n",
    "response = qa_high_temp({'query': question})\n",
    "answer = response.get('result').split('Helpful Answer:')[1].strip()\n",
    "explanation = response.get('source_documents', [])\n",
    "print(answer)\n",
    "explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask a question\n",
    "question = 'what happened with the seven tailed beasts?'\n",
    "response = qa_high_temp({'query': question})\n",
    "answer = response.get('result').split('Helpful Answer:')[1].strip()\n",
    "explanation = response.get('source_documents', [])\n",
    "print(answer)\n",
    "explanation\n",
    "# It answered well in the beginning and then hallucinated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask a question\n",
    "question = 'are there any species similar to snakes?'\n",
    "response = qa_high_temp({'query': question})\n",
    "answer = response.get('result').split('Helpful Answer:')[1].strip()\n",
    "explanation = response.get('source_documents', [])\n",
    "print(answer)\n",
    "explanation\n",
    "# It also answered well in the beginning and then hallucinated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask a question\n",
    "question = 'summarize about venomous snakes'\n",
    "response = qa_high_temp({'query': question})\n",
    "answer = response.get('result').split('Helpful Answer:')[1].strip()\n",
    "explanation = response.get('source_documents', [])\n",
    "print(answer)\n",
    "explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask a question\n",
    "question = 'how to cook rice?'\n",
    "response = qa_high_temp({'query': question})\n",
    "answer = response.get('result').split('Helpful Answer:')[1].strip()\n",
    "explanation = response.get('source_documents', [])\n",
    "print(answer)\n",
    "explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask a question\n",
    "question = 'hi, how are you?'\n",
    "response = qa_high_temp({'query': question})\n",
    "answer = response.get('result').split('Helpful Answer:')[1].strip()\n",
    "explanation = response.get('source_documents', [])\n",
    "print(answer)\n",
    "explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try lower temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = 0.8\n",
    "max_length = 300\n",
    "llm_model = 'bigscience/bloom'\n",
    "\n",
    "# Load LLM\n",
    "llm = HuggingFaceHub(\n",
    "    repo_id=llm_model,\n",
    "    model_kwargs={'temperature': temperature, 'max_length': max_length},\n",
    "    huggingfacehub_api_token=token\n",
    ")\n",
    "\n",
    "# Create the chatbot\n",
    "qa_low_temp = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type='stuff',\n",
    "    retriever=loaded_db.as_retriever(),\n",
    "    return_source_documents=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask a question\n",
    "question = 'what is naruto?'\n",
    "response = qa_low_temp({'query': question})\n",
    "answer = response.get('result').split('Helpful Answer:')[1].strip()\n",
    "explanation = response.get('source_documents', [])\n",
    "print(answer)\n",
    "explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask a question\n",
    "question = 'what happened with the 7 tailed beasts?'\n",
    "response = qa_low_temp({'query': question})\n",
    "answer = response.get('result').split('Helpful Answer:')[1].strip()\n",
    "explanation = response.get('source_documents', [])\n",
    "print(answer)\n",
    "explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask a question\n",
    "question = 'summarize about venomous snakes'\n",
    "response = qa_low_temp({'query': question})\n",
    "answer = response.get('result').split('Helpful Answer:')[1].strip()\n",
    "explanation = response.get('source_documents', [])\n",
    "print(answer)\n",
    "explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try LangChain memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = 1\n",
    "max_length = 400\n",
    "llm_model = 'mistralai/Mistral-7B-Instruct-v0.2'\n",
    "\n",
    "# Load LLM\n",
    "llm = HuggingFaceHub(\n",
    "    repo_id=llm_model,\n",
    "    model_kwargs={'temperature': temperature, 'max_length': max_length},\n",
    "    huggingfacehub_api_token=token\n",
    ")\n",
    "\n",
    "memory = ConversationBufferWindowMemory(\n",
    "    k=2,\n",
    "    memory_key=\"chat_history\",\n",
    "    output_key=\"answer\",\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "qa_conversation = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    chain_type='stuff',\n",
    "    retriever=loaded_db.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    memory=memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'who is naruto?'\n",
    "response = qa_conversation({'question': question})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask a question\n",
    "# question = 'who is naruto?'\n",
    "# response = qa_conversation({'question': question})\n",
    "answer = response.get('answer').split('Helpful Answer:')[-1].strip()\n",
    "explanation = response.get('source_documents', [])\n",
    "print(answer)\n",
    "explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask a question\n",
    "question = 'do you know whom I am talking about?'\n",
    "response = qa_conversation({'question': question})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask a question\n",
    "# question = 'do you know whom I am talking about?'\n",
    "# response = qa_conversation({'question': question})\n",
    "answer = response.get('answer').split('Helpful Answer:')[-1].strip()\n",
    "explanation = response.get('source_documents', [])\n",
    "print(answer)\n",
    "explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask a question\n",
    "question = 'who is his team member?'\n",
    "response = qa_conversation({'question': question})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.get('answer').split('Standalone question:')[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask a question\n",
    "# question = 'who is his team member?'\n",
    "# response = qa_conversation({'question': question})\n",
    "answer = response.get('answer').split('Helpful Answer:')[-1].strip()\n",
    "explanation = response.get('source_documents', [])\n",
    "print(answer)\n",
    "explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask a question\n",
    "question = 'who are the other teams?'\n",
    "response = qa_conversation({'question': question})\n",
    "answer = response.get('answer').split('Helpful Answer:')[-1].strip()\n",
    "explanation = response.get('source_documents', [])\n",
    "print(answer)\n",
    "explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask a question\n",
    "question = 'are there any species similar to snakes?'\n",
    "response = qa_conversation({'question': question})\n",
    "answer = response.get('answer').split('Helpful Answer:')[-1].strip()\n",
    "explanation = response.get('source_documents', [])\n",
    "print(answer)\n",
    "explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask a question\n",
    "question = 'are they the only limbless animals?'\n",
    "response = qa_conversation({'question': question})\n",
    "answer = response.get('answer').split('Helpful Answer:')[-1].strip()\n",
    "explanation = response.get('source_documents', [])\n",
    "print(answer)\n",
    "explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask a question\n",
    "question = 'Hi, i am a data scientist. How are you?'\n",
    "response = qa_conversation({'question': question})\n",
    "answer = response.get('answer').split('Helpful Answer:')[-1].strip()\n",
    "explanation = response.get('source_documents', [])\n",
    "print(answer)\n",
    "explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4780475,
     "sourceId": 8096385,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30683,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
